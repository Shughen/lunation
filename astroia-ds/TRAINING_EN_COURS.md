# ğŸ¤– ENTRAÃNEMENT ML EN COURS

**Date de lancement:** 5 novembre 2025  
**Statut:** ğŸŸ¢ **EN COURS**

---

## ğŸ“Š CONFIGURATION

**Dataset:** `data_external/dataset_big.csv`  
**Taille:** 500,000 lignes  
**Algorithm:** XGBoost + Optuna  
**Trials:** 1,000 optimisations  
**DurÃ©e estimÃ©e:** **~22 heures**

**PID:** 5929

---

## ğŸ“ FICHIERS

**Logs:**
```
outputs/logs/training_night_20251105_*.log
```

**ModÃ¨le final:**
```
outputs/models/xgb_best.pkl
```

**MÃ©triques:**
```
outputs/best_params.json
```

**Graphiques:**
```
outputs/reports/optuna_history.png
```

---

## ğŸ” SUIVRE LA PROGRESSION

### Voir les logs en direct
```bash
cd /Users/remibeaurain/astroia/astroia-ds
tail -f outputs/logs/training_night_*.log
```

### VÃ©rifier que Ã§a tourne
```bash
ps aux | grep train_optuna | grep -v grep
```

### Voir le PID
```bash
cat outputs/logs/training.pid
```

---

## â¸ï¸ ARRÃŠTER L'ENTRAÃNEMENT

```bash
kill 5929
# OU
kill $(cat outputs/logs/training.pid)
```

---

## ğŸ“ˆ PROGRESSION ATTENDUE

| Heure | Trials | Progression | Best ROC-AUC estimÃ© |
|-------|--------|-------------|---------------------|
| +2h | ~90 | 9% | 0.72 |
| +6h | ~270 | 27% | 0.76 |
| +12h | ~545 | 54% | 0.79 |
| +18h | ~818 | 82% | 0.82 |
| +22h | 1000 | 100% | **0.85+** âœ… |

---

## âœ… RÃ‰SULTATS FINAUX

**Le modÃ¨le sera disponible dans :**
```
outputs/models/xgb_best.pkl
```

**Ã€ copier vers l'API :**
```bash
cp outputs/models/xgb_best.pkl ../astro-ia-api/api/ml/xgb_best.pkl
```

**Puis redÃ©ployer :**
```bash
cd ../astro-ia-api
# RedÃ©ployer sur Vercel
```

---

## ğŸ¯ APRÃˆS L'ENTRAÃNEMENT

1. **Copier le modÃ¨le** vers l'API
2. **VÃ©rifier les mÃ©triques** (ROC-AUC > 0.80)
3. **Tester** l'analyse Parent-Enfant dans l'app
4. **Comparer** les rÃ©sultats avec l'ancien modÃ¨le

---

## ğŸ”§ PARAMÃˆTRES D'OPTIMISATION

**HyperparamÃ¨tres optimisÃ©s :**
- `n_estimators`: 400-4000 (nombre d'arbres)
- `max_depth`: 3-10 (profondeur)
- `learning_rate`: 0.001-0.2 (taux d'apprentissage)
- `subsample`: 0.6-1.0 (Ã©chantillonnage)
- `colsample_bytree`: 0.6-1.0 (features)
- `min_child_weight`: 1-20 (rÃ©gularisation)
- `gamma`: 0-5 (splitting)
- `reg_lambda`: 0.001-10 (L2)
- `reg_alpha`: 0.001-10 (L1)

**StratÃ©gie:**
- Optuna TPE (Tree-structured Parzen Estimator)
- Maximisation ROC-AUC
- 1000 trials pour exploration exhaustive

---

## ğŸ’» UTILISATION DU MAC

**Pendant l'entraÃ®nement:**
- âœ… Navigation web OK
- âœ… Bureautique OK
- âš ï¸ Pas de jeux/vidÃ©o lourds (CPU utilisÃ© Ã  ~80%)
- âš ï¸ Le Mac peut chauffer
- âš ï¸ Batterie se dÃ©charge plus vite

**Recommandation:**
- Laisser le Mac branchÃ©
- Ne pas le mettre en veille
- VÃ©rifier toutes les 4-6h que Ã§a tourne

---

## ğŸ“ EN CAS DE PROBLÃˆME

### Le processus s'est arrÃªtÃ©

```bash
# VÃ©rifier le dernier log
tail -50 outputs/logs/training_night_*.log

# Relancer si nÃ©cessaire
source env/bin/activate
python src/train_optuna.py --data data_external/dataset_big.csv --trials 1000
```

### MÃ©moire insuffisante

```bash
# RÃ©duire le nombre de trials
python src/train_optuna.py --data data_external/dataset_big.csv --trials 500
```

### Mac en surchauffe

```bash
# ArrÃªter temporairement
kill $(cat outputs/logs/training.pid)

# Relancer plus tard avec moins de CPU
python src/train_optuna.py --data data_external/dataset_big.csv --trials 500
```

---

**âœ… EntraÃ®nement lancÃ© ! Rendez-vous dans 22h ! ğŸš€**

**Tu peux vÃ©rifier la progression : `tail -f outputs/logs/training_night_*.log`**

